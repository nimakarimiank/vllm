root@dsosws01:/vllm-workspace# vllm serve deepseek-ai/deepseek-llm-7b-chat  --distributed-executor-backend ray \
  --tensor-parallel-size 2 
INFO 11-23 11:51:19 [scheduler.py:207] Chunked prefill is enabled with max_num_batched_tokens=2048.
(APIServer pid=1743) INFO 11-23 11:51:19 [api_server.py:2056] vLLM API server version 0.11.2.dev201+g55c21c883
(APIServer pid=1743) INFO 11-23 11:51:19 [utils.py:253] non-default args: {'model_tag': 'deepseek-ai/deepseek-llm-7b-chat', 'model': 'deepseek-ai/deepseek-llm-7b-chat', 'distributed_executor_backend': 'ray', 'tensor_parallel_size': 2}
(APIServer pid=1743) INFO 11-23 11:51:20 [model.py:630] Resolved architecture: LlamaForCausalLM
(APIServer pid=1743) INFO 11-23 11:51:20 [model.py:1745] Using max model len 4096
(APIServer pid=1743) INFO 11-23 11:51:21 [scheduler.py:207] Chunked prefill is enabled with max_num_batched_tokens=2048.
(EngineCore_DP0 pid=1783) INFO 11-23 11:51:24 [core.py:93] Initializing a V1 LLM engine (v0.11.2.dev201+g55c21c883) with config: model='deepseek-ai/deepseek-llm-7b-chat', speculative_config=None, tokenizer='deepseek-ai/deepseek-llm-7b-chat', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=deepseek-ai/deepseek-llm-7b-chat, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
(EngineCore_DP0 pid=1783) WARNING 11-23 11:51:24 [ray_utils.py:331] Tensor parallel size (2) exceeds available GPUs (1). This may result in Ray placement group allocation failures. Consider reducing tensor_parallel_size to 1 or less, or ensure your Ray cluster has 2 GPUs available.
(EngineCore_DP0 pid=1783) 2025-11-23 11:51:24,947	INFO worker.py:1837 -- Connecting to existing Ray cluster at address: 192.168.0.101:6379...
(EngineCore_DP0 pid=1783) 2025-11-23 11:51:24,955	INFO worker.py:2023 -- Connected to Ray cluster.
(EngineCore_DP0 pid=1783) /usr/local/lib/python3.12/dist-packages/ray/_private/worker.py:2062: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
(EngineCore_DP0 pid=1783)   warnings.warn(
(EngineCore_DP0 pid=1783) INFO 11-23 11:51:24 [ray_utils.py:396] No current placement group found. Creating a new placement group.
(EngineCore_DP0 pid=1783) WARNING 11-23 11:51:25 [ray_utils.py:207] tensor_parallel_size=2 is bigger than a reserved number of GPUs (1 GPUs) in a node 113d2eeec74dee6a6bd8d0eaee43aa412c08c0c7f38d583766589e89. Tensor parallel workers can be spread out to 2+ nodes which can degrade the performance unless you have fast interconnect across nodes, like Infiniband. To resolve this issue, make sure you have more than 2 GPUs available at each node.
(EngineCore_DP0 pid=1783) WARNING 11-23 11:51:25 [ray_utils.py:207] tensor_parallel_size=2 is bigger than a reserved number of GPUs (1 GPUs) in a node d9886121e805a6049486cdfbb9bbdffa233995773906f7126e1035e5. Tensor parallel workers can be spread out to 2+ nodes which can degrade the performance unless you have fast interconnect across nodes, like Infiniband. To resolve this issue, make sure you have more than 2 GPUs available at each node.
(EngineCore_DP0 pid=1783) INFO 11-23 11:51:27 [ray_env.py:66] RAY_NON_CARRY_OVER_ENV_VARS from config: set()
(EngineCore_DP0 pid=1783) INFO 11-23 11:51:27 [ray_env.py:69] Copying the following environment variables to workers: ['VLLM_USAGE_SOURCE', 'LD_LIBRARY_PATH', 'VLLM_WORKER_MULTIPROC_METHOD']
(EngineCore_DP0 pid=1783) INFO 11-23 11:51:27 [ray_env.py:74] If certain env vars should NOT be copied, add them to /root/.config/vllm/ray_non_carry_over_env_vars.json file
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=474) WARNING 11-23 11:51:28 [worker_base.py:301] Missing `shared_worker_lock` argument from executor. This argument is needed for mm_processor_cache_type='shm'.
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) INFO 11-23 11:51:28 [parallel_state.py:1217] world_size=2 rank=1 local_rank=0 distributed_init_method=tcp://192.168.0.101:49601 backend=nccl
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842] EngineCore failed to start.
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842] Traceback (most recent call last):
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 609, in __init__
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     super().__init__(
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     self._init_executor()
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/executor/ray_executor.py", line 97, in _init_executor
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     self._init_workers_ray(placement_group)
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/executor/ray_executor.py", line 370, in _init_workers_ray
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     self.collective_rpc("init_device")
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/executor/ray_executor.py", line 493, in collective_rpc
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     return ray.get(ray_worker_outputs, timeout=timeout)
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py", line 2972, in get
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     values, debugger_breakpoint = worker.get_objects(
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]                                   ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py", line 1031, in get_objects
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     raise value.as_instanceof_cause()
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842] ray.exceptions.RayTaskError(RuntimeError): ray::RayWorkerWrapper.execute_method() (pid=255, ip=192.168.0.103, actor_id=760db004a0bb6b7368f9ba1604000000, repr=<vllm.v1.executor.ray_utils.RayWorkerWrapper object at 0x7b6528f27e00>)
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/worker_base.py", line 345, in execute_method
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     raise e
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/worker_base.py", line 334, in execute_method
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     return run_method(self, method, args, kwargs)
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/serial_utils.py", line 479, in run_method
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/worker_base.py", line 326, in init_device
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     self.worker.init_device()  # type: ignore
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 205, in init_device
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     init_worker_distributed_environment(
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 870, in init_worker_distributed_environment
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     init_distributed_environment(
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/vllm/distributed/parallel_state.py", line 1256, in init_distributed_environment
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     _WORLD = init_world_group(ranks, local_rank, backend)
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/vllm/distributed/parallel_state.py", line 1044, in init_world_group
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     return GroupCoordinator(
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/vllm/distributed/parallel_state.py", line 332, in __init__
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     cpu_group = torch.distributed.new_group(ranks, backend="gloo")
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/c10d_logger.py", line 95, in wrapper
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     func_return = func(*args, **kwargs)
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py", line 5276, in new_group
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     return _new_group_with_tag(
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py", line 5366, in _new_group_with_tag
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     pg, pg_store = _new_process_group_helper(
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py", line 1996, in _new_process_group_helper
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]     backend_class = ProcessGroupGloo(
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842]                     ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) ERROR 11-23 11:51:28 [core.py:842] RuntimeError: Gloo connectFullMesh failed with [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:152] timed out connecting: SO_ERROR: Connection refused, remote=[127.0.1.1]:60335$1
(EngineCore_DP0 pid=1783) Process EngineCore_DP0:
(EngineCore_DP0 pid=1783) Traceback (most recent call last):
(EngineCore_DP0 pid=1783)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=1783)     self.run()
(EngineCore_DP0 pid=1783)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=1783)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
(EngineCore_DP0 pid=1783)     raise e
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
(EngineCore_DP0 pid=1783)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1783)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 609, in __init__
(EngineCore_DP0 pid=1783)     super().__init__(
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1783)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=1783)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=1783)     self._init_executor()
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/executor/ray_executor.py", line 97, in _init_executor
(EngineCore_DP0 pid=1783)     self._init_workers_ray(placement_group)
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/executor/ray_executor.py", line 370, in _init_workers_ray
(EngineCore_DP0 pid=1783)     self.collective_rpc("init_device")
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/executor/ray_executor.py", line 493, in collective_rpc
(EngineCore_DP0 pid=1783)     return ray.get(ray_worker_outputs, timeout=timeout)
(EngineCore_DP0 pid=1783)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
(EngineCore_DP0 pid=1783)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1783)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
(EngineCore_DP0 pid=1783)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1783)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py", line 2972, in get
(EngineCore_DP0 pid=1783)     values, debugger_breakpoint = worker.get_objects(
(EngineCore_DP0 pid=1783)                                   ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py", line 1031, in get_objects
(EngineCore_DP0 pid=1783)     raise value.as_instanceof_cause()
(EngineCore_DP0 pid=1783) ray.exceptions.RayTaskError(RuntimeError): ray::RayWorkerWrapper.execute_method() (pid=255, ip=192.168.0.103, actor_id=760db004a0bb6b7368f9ba1604000000, repr=<vllm.v1.executor.ray_utils.RayWorkerWrapper object at 0x7b6528f27e00>)
(EngineCore_DP0 pid=1783)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/worker_base.py", line 345, in execute_method
(EngineCore_DP0 pid=1783)     raise e
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/worker_base.py", line 334, in execute_method
(EngineCore_DP0 pid=1783)     return run_method(self, method, args, kwargs)
(EngineCore_DP0 pid=1783)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/serial_utils.py", line 479, in run_method
(EngineCore_DP0 pid=1783)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1783)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/worker_base.py", line 326, in init_device
(EngineCore_DP0 pid=1783)     self.worker.init_device()  # type: ignore
(EngineCore_DP0 pid=1783)     ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 205, in init_device
(EngineCore_DP0 pid=1783)     init_worker_distributed_environment(
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 870, in init_worker_distributed_environment
(EngineCore_DP0 pid=1783)     init_distributed_environment(
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/vllm/distributed/parallel_state.py", line 1256, in init_distributed_environment
(EngineCore_DP0 pid=1783)     _WORLD = init_world_group(ranks, local_rank, backend)
(EngineCore_DP0 pid=1783)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/vllm/distributed/parallel_state.py", line 1044, in init_world_group
(EngineCore_DP0 pid=1783)     return GroupCoordinator(
(EngineCore_DP0 pid=1783)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/vllm/distributed/parallel_state.py", line 332, in __init__
(EngineCore_DP0 pid=1783)     cpu_group = torch.distributed.new_group(ranks, backend="gloo")
(EngineCore_DP0 pid=1783)                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/c10d_logger.py", line 95, in wrapper
(EngineCore_DP0 pid=1783)     func_return = func(*args, **kwargs)
(EngineCore_DP0 pid=1783)                   ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py", line 5276, in new_group
(EngineCore_DP0 pid=1783)     return _new_group_with_tag(
(EngineCore_DP0 pid=1783)            ^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py", line 5366, in _new_group_with_tag
(EngineCore_DP0 pid=1783)     pg, pg_store = _new_process_group_helper(
(EngineCore_DP0 pid=1783)                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783)   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py", line 1996, in _new_process_group_helper
(EngineCore_DP0 pid=1783)     backend_class = ProcessGroupGloo(
(EngineCore_DP0 pid=1783)                     ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) RuntimeError: Gloo connectFullMesh failed with [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:152] timed out connecting: SO_ERROR: Connection refused, remote=[127.0.1.1]:60335$1
(EngineCore_DP0 pid=1783) INFO 11-23 11:51:28 [ray_executor.py:121] Shutting down Ray distributed executor. If you see error log from logging.cc regarding SIGTERM received, please ignore because this is the expected termination process in Ray.
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344] Error executing method 'init_device'. This might cause deadlock in distributed execution.
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344] Traceback (most recent call last):
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/worker_base.py", line 334, in execute_method
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]     return run_method(self, method, args, kwargs)
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/serial_utils.py", line 479, in run_method
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]   File "/usr/local/lib/python3.12/dist-packages/ray/util/tracing/tracing_helper.py", line 461, in _resume_span
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]     return method(self, *_args, **_kwargs)
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/worker_base.py", line 326, in init_device
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]     self.worker.init_device()  # type: ignore
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]     ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 205, in init_device
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]     init_worker_distributed_environment(
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 870, in init_worker_distributed_environment
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]     init_distributed_environment(
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]   File "/usr/local/lib/python3.12/dist-packages/vllm/distributed/parallel_state.py", line 1256, in init_distributed_environment
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]     _WORLD = init_world_group(ranks, local_rank, backend)
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]   File "/usr/local/lib/python3.12/dist-packages/vllm/distributed/parallel_state.py", line 1044, in init_world_group
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]     return GroupCoordinator(
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]   File "/usr/local/lib/python3.12/dist-packages/vllm/distributed/parallel_state.py", line 332, in __init__
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]     cpu_group = torch.distributed.new_group(ranks, backend="gloo")
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/c10d_logger.py", line 95, in wrapper
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]     func_return = func(*args, **kwargs)
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]                   ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py", line 5276, in new_group
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]     return _new_group_with_tag(
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]            ^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py", line 5366, in _new_group_with_tag
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]     pg, pg_store = _new_process_group_helper(
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py", line 1996, in _new_process_group_helper
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]     backend_class = ProcessGroupGloo(
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344]                     ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) ERROR 11-23 11:51:28 [worker_base.py:344] RuntimeError: Gloo connectFullMesh failed with [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:152] timed out connecting: SO_ERROR: Connection refused, remote=[127.0.1.1]:60335$1
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) [/pytorch/third_party/gloo/gloo/transport/tcp/debug_logger.cc:9] ERROR failed to connect, willRetry=1, retry=1, retryLimit=3, rank=1, size=2, local=[127.0.0.1]:14497, remote=[127.0.1.1]:60335$1, error=SO_ERROR: Connection refused, remote=[127.0.1.1]:60335$1
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) [/pytorch/third_party/gloo/gloo/transport/tcp/debug_logger.cc:9] ERROR failed to connect, willRetry=1, retry=2, retryLimit=3, rank=1, size=2, local=[127.0.0.1]:15009, remote=[127.0.1.1]:60335$1, error=SO_ERROR: Connection refused, remote=[127.0.1.1]:60335$1
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) [/pytorch/third_party/gloo/gloo/transport/tcp/debug_logger.cc:9] ERROR failed to connect, willRetry=1, retry=3, retryLimit=3, rank=1, size=2, local=[127.0.0.1]:16033, remote=[127.0.1.1]:60335$1, error=SO_ERROR: Connection refused, remote=[127.0.1.1]:60335$1
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) [/pytorch/third_party/gloo/gloo/transport/tcp/debug_logger.cc:9] ERROR failed to connect, willRetry=0, retry=4, retryLimit=3, rank=1, size=2, local=[127.0.0.1]:20129, remote=[127.0.1.1]:60335$1, error=SO_ERROR: Connection refused, remote=[127.0.1.1]:60335$1
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) [rank1]:[E1123 11:51:28.039120438 ProcessGroupGloo.cpp:71] Gloo connectFullMesh failed with [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:152] timed out connecting: SO_ERROR: Connection refused, remote=[127.0.1.1]:60335$1
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) [rank1]:[W1123 11:51:28.449777077 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=255, ip=192.168.0.103) WARNING 11-23 11:51:28 [worker_base.py:301] Missing `shared_worker_lock` argument from executor. This argument is needed for mm_processor_cache_type='shm'.
(EngineCore_DP0 pid=1783) (RayWorkerWrapper pid=474) INFO 11-23 11:51:28 [parallel_state.py:1217] world_size=2 rank=0 local_rank=0 distributed_init_method=tcp://192.168.0.101:49601 backend=nccl
(APIServer pid=1743) Traceback (most recent call last):
(APIServer pid=1743)   File "/usr/local/bin/vllm", line 10, in <module>
(APIServer pid=1743)     sys.exit(main())
(APIServer pid=1743)              ^^^^^^
(APIServer pid=1743)   File "/usr/local/lib/python3.12/dist-packages/vllm/entrypoints/cli/main.py", line 73, in main
(APIServer pid=1743)     args.dispatch_function(args)
(APIServer pid=1743)   File "/usr/local/lib/python3.12/dist-packages/vllm/entrypoints/cli/serve.py", line 60, in cmd
(APIServer pid=1743)     uvloop.run(run_server(args))
(APIServer pid=1743)   File "/usr/local/lib/python3.12/dist-packages/uvloop/__init__.py", line 96, in run
(APIServer pid=1743)     return __asyncio.run(
(APIServer pid=1743)            ^^^^^^^^^^^^^^
(APIServer pid=1743)   File "/usr/lib/python3.12/asyncio/runners.py", line 195, in run
(APIServer pid=1743)     return runner.run(main)
(APIServer pid=1743)            ^^^^^^^^^^^^^^^^
(APIServer pid=1743)   File "/usr/lib/python3.12/asyncio/runners.py", line 118, in run
(APIServer pid=1743)     return self._loop.run_until_complete(task)
(APIServer pid=1743)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(APIServer pid=1743)   File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
(APIServer pid=1743)   File "/usr/local/lib/python3.12/dist-packages/uvloop/__init__.py", line 48, in wrapper
(APIServer pid=1743)     return await main
(APIServer pid=1743)            ^^^^^^^^^^
(APIServer pid=1743)   File "/usr/local/lib/python3.12/dist-packages/vllm/entrypoints/openai/api_server.py", line 2106, in run_server
(APIServer pid=1743)     await run_server_worker(listen_address, sock, args, **uvicorn_kwargs)
(APIServer pid=1743)   File "/usr/local/lib/python3.12/dist-packages/vllm/entrypoints/openai/api_server.py", line 2125, in run_server_worker
(APIServer pid=1743)     async with build_async_engine_client(
(APIServer pid=1743)                ^^^^^^^^^^^^^^^^^^^^^^^^^^
(APIServer pid=1743)   File "/usr/lib/python3.12/contextlib.py", line 210, in __aenter__
(APIServer pid=1743)     return await anext(self.gen)
(APIServer pid=1743)            ^^^^^^^^^^^^^^^^^^^^^
(APIServer pid=1743)   File "/usr/local/lib/python3.12/dist-packages/vllm/entrypoints/openai/api_server.py", line 196, in build_async_engine_client
(APIServer pid=1743)     async with build_async_engine_client_from_engine_args(
(APIServer pid=1743)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(APIServer pid=1743)   File "/usr/lib/python3.12/contextlib.py", line 210, in __aenter__
(APIServer pid=1743)     return await anext(self.gen)
(APIServer pid=1743)            ^^^^^^^^^^^^^^^^^^^^^
(APIServer pid=1743)   File "/usr/local/lib/python3.12/dist-packages/vllm/entrypoints/openai/api_server.py", line 237, in build_async_engine_client_from_engine_args
(APIServer pid=1743)     async_llm = AsyncLLM.from_vllm_config(
(APIServer pid=1743)                 ^^^^^^^^^^^^^^^^^^^^^^^^^^
(APIServer pid=1743)   File "/usr/local/lib/python3.12/dist-packages/vllm/utils/func_utils.py", line 116, in inner
(APIServer pid=1743)     return fn(*args, **kwargs)
(APIServer pid=1743)            ^^^^^^^^^^^^^^^^^^^
(APIServer pid=1743)   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/async_llm.py", line 219, in from_vllm_config
(APIServer pid=1743)     return cls(
(APIServer pid=1743)            ^^^^
(APIServer pid=1743)   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/async_llm.py", line 133, in __init__
(APIServer pid=1743)     self.engine_core = EngineCoreClient.make_async_mp_client(
(APIServer pid=1743)                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(APIServer pid=1743)   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core_client.py", line 121, in make_async_mp_client
(APIServer pid=1743)     return AsyncMPClient(*client_args)
(APIServer pid=1743)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(APIServer pid=1743)   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core_client.py", line 808, in __init__
(APIServer pid=1743)     super().__init__(
(APIServer pid=1743)   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core_client.py", line 469, in __init__
(APIServer pid=1743)     with launch_core_engines(vllm_config, executor_class, log_stats) as (
(APIServer pid=1743)          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(APIServer pid=1743)   File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
(APIServer pid=1743)     next(self.gen)
(APIServer pid=1743)   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/utils.py", line 907, in launch_core_engines
(APIServer pid=1743)     wait_for_engine_startup(
(APIServer pid=1743)   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/utils.py", line 964, in wait_for_engine_startup
(APIServer pid=1743)     raise RuntimeError(
(APIServer pid=1743) RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}
root@dsosws01:/vllm-workspace# 
